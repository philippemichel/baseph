---
title: "baseph_vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{baseph_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, warning = FALSE, message = FALSE
)
```

```{r setup}
library(labelled)
library(tidyverse)
library(baseph)
library(binom)
library(colorspace)
```

Pour tous les exemples suivant on utilise deux fichiers (dans le dossier `data`: 

- **patient.csv** qui contient des données fictives sur des patients.
- **noms.sv** qui contient une colonne `code` avec les noms des variables (ex : *igs2*) & une colonne `nom` qui contient les vrais noms de la variable pour un affichage clair dans les tableaux, graphiques etc. (ex : *IGS 2*). Un exmeple d'utilisation pourrait être :

```{r import}
# Création du vecteur de noms
nn <- read_csv("../data/noms.csv")
bnom <- nn$nom
# Import de la base de données & incorporation des labels.
pat <- debutph("../data/patients.csv", bnom)
```

# Avant l'analyse des données

## Calcul du nombre de cas

Quelques calculs du nombre de cas nécessaires pour des circonstances particulières.


### Non infériorité & équivalence. 

calcul du nombre de cas pour des études d'équivalence ou de non infériorité quand le test principal repose sur une variable binaire.

```{r noninf, }
nb.noninf.ph(po = 0.5,# proportion sur le groupe contrôle
             dl = 0.1, # 	déviation jugée comme acceptable
             zalpha = 0.05, # risque alpha
             zbeta = 0.2) # risque beta
```

```{r equi}
nb.equi.ph(po=0.5, dl = 0.1, zalpha = 0.05, zbeta = 0.2)
```

### Étude observationelle simple

Cette méthode permet d'avoir une estimation du nombre de cas nécessaire dans une étude purement observationnelle, sans test donc pas de calcul précis possible. Il faut néanmoins définir la marge d'erreur admissible sur les résultats.

```{r obs}
nb.obs.ph(px = 0.5, ex = 0.1, np = 1e5)
```


## Randomisation


Cette fonction, basée sur la fonction `blockrand` du package homonyme permet de créer les tables de randomisation (aléatoire) pour une étude sur plusieurs centres & pour deux classes (traitement 1 vs traitement B par ex.) ou plus. 

```{r rand, eval = FALSE} 
listrandph(nbcent = 1, # nombre de centres
          nbtrait = 2, #Nombre de modalités
          nbcas = 100 # nb de cas total voulu
           )
```
La sortie consiste en un fichier global & un par centre (csv).


# Tableau 1

Le premier tableau d'une étude est toujours un tableau simple, sans test (enfin presque toujours). Pour les valeurs numériques on peut choisir l’affichage de la moyenne ± écart-type (test = "moy") ou de la médiane (quartiles) (test = "med").

```{r tab1}
tab1ph(dfx = pat, test = "med", titre = "Escarre", capt = "Tableau 1")
```


# Tableaux comparatifs.

## Analyse univariée

Ce tableau sert à présenter les résultats de tests variable par variable.  On peut en particulier définir si on considère que les données numériques ont une distribution normale (présentation des résultats en moyenne ± écart-type, test de Student) ou non (présentation en médiane (quartiles), test de Wilcoxon).

```{r tabc}
tabcph(dfx = patients, tri = escarre, test = "moy", titre = "Escarre", capt = "Tableau 1")
```


## Analyse multivariée

On peut compléter l'analyse par une étude en multivariée par régression logistique.
La fonction `tabregph` prend comme principal argument le résultat d'un régression (grand nombre de modèles possibles, voir <https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html#supported-models>).


```{r treg}
ll <- glm(escarre~ age + admission + igs2, data = patients, family = "binomial")
# tabregph(reg = ll, titre = "Facteurs de risque d'escarre" )
```




